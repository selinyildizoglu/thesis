---
title: "R Notebook" 
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

#week1quiz
```{r} 
mean("Ozone")
[1] NA
Warning message:
In mean.default("Ozone") : argument is not numeric or logical: returning NA
> mean(df$Ozone)
Error in df$Ozone : object of type 'closure' is not subsettable
> mean(df1$Ozone)
Error in mean(df1$Ozone) : object 'df1' not found
> mean(hw1_data$Ozone)
[1] NA
> mean(hw1_data$Ozone, na.rm=TRUE) #correct
[1] 42.12931
> mean(hw1_data$Temp)
[1] 77.88235
#"What is the mean of "Temp" when "Month" is equal to 6?"
> mean(hw1_data[hw1_data$Month==6,]$Temp) 
[1] 79.1

#"Extract the subset of rows of the data frame where Ozone values are above 31 and Temp values are above 90. What is the mean of Solar.R in this subset?"
> mean(hw1_data[hw1_data$Ozone>31][hw1_data$Temp>90]$Solar.R)
Error: Can't use NA as column index with `[` at positions 5, 10, 25, 26, 27, and 32 more.
Run `rlang::last_error()` to see where the error occurred.
> rlang::last_error
function () 
{
    if (is_null(last_error_env$cnd)) {
        abort("Can't show last error because no error was recorded yet")
    }
    cnd <- last_error_env$cnd
    cnd$rlang$internal$from_last_error <- TRUE
    cnd
}
<bytecode: 0x10fcf9d30>
<environment: namespace:rlang>
> mean(hw1_data[hw1_data$Ozone>31, hw1_data$Temp>90]$Solar.R)
Error: Must subset columns with a valid subscript vector.
ℹ Logical subscripts must match the size of the indexed input.
x The input has size 6 but the subscript `hw1_data$Temp > 90` has size 153.
Run `rlang::last_error()` to see where the error occurred.
> mean(hw1_data[hw1_data$Ozone>31]$Solar.R)
Error: Can't use NA as column index with `[` at positions 5, 10, 25, 26, 27, and 32 more.
Run `rlang::last_error()` to see where the error occurred.
> mean(hw1_data[hw1_data$Ozone>31]$Solar.R, na.rm=TRUE)
Error: Can't use NA as column index with `[` at positions 5, 10, 25, 26, 27, and 32 more.
Run `rlang::last_error()` to see where the error occurred.
> mean(hw1_data[hw1_data$Ozone>31, na.rm=TRUE]$Solar.R, na.rm=TRUE)
[1] 215.0545
> mean(hw1_data[hw1_data$Ozone>31, na.rm=TRUE][hm1_data$Temp>90]$Solar.R, na.rm=TRUE)
Error in `[.tbl_df`(hw1_data[hw1_data$Ozone > 31, na.rm = TRUE], hm1_data$Temp >  : 
  object 'hm1_data' not found
> mean(hw1_data[hw1_data$Ozone>31, na.rm=TRUE][hw1_data$Temp>90]$Solar.R, na.rm=TRUE)
Error: Must subset columns with a valid subscript vector.
ℹ Logical subscripts must match the size of the indexed input.
x The input has size 6 but the subscript `hw1_data$Temp > 90` has size 153.
Run `rlang::last_error()` to see where the error occurred.
> mean(hw1_data[hw1_data$Ozone>31, na.rm=TRUE][hw1_data$Temp>90, na.rm=TRUE]$Solar.R, na.rm=TRUE)
Error: Must subset rows with a valid subscript vector.
ℹ Logical subscripts must match the size of the indexed input.
x The input has size 95 but the subscript `hw1_data$Temp > 90` has size 153.
Run `rlang::last_error()` to see where the error occurred.

#correct answer below
> mean(hw1_data[hw1_data$Ozone>31 & hw1_data$Temp>90, ]$Solar.R, na.rm=T)
[1] 212.8
```

#week2course 

#Introduction to Control Structures
#if,else: testing a condition
#for: execute a loop a fixed number of tiimes
#while: execute a loop while a condition is true
#repeat: execute an infite loop
#break: break the execution of a loop
#next: skip an interaction of a loop
#return: exit a function

#if-else

if(<condition>) {
##do somethinig
} else {
## do somethiing else

#example

if(x>3) {
  y <- 10
} else {
  y <- 0
}

#used tab to create indentation, but not sure why space is needed or how necessary, or if correct to use tab. 

#also valid:

y <- if(x > 3) {
  10
} else {
  0
}

#else is not always necessary

#can test multiple conditions in a row

#For loops

for(i in 1:10) {
print (i)
}
```{r}
for(i in 1:10) {
+     print (i)
+ }
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
```

```{r}
x <- c("a", "b", "c", "d")
> for (i in 1:4) {} #incorrect, need to delete second bracket before entering next line
> for (i in 1:4) { 
+ print(x[i])
+ }
[1] "a"
[1] "b"
[1] "c"
[1] "d"
```

for (i in seq_along(x)) {
  print(x[i])
}     
#seq_along takes a vector as an input and it creates an integer sequence that's equal to the length of that vector 
```{r}
> for (i in seq_along(x)) {
+     print(x[i])
+ }
[1] "a"
[1] "b"
[1] "c"
[1] "d"
```

for(letter in x) {
  print(letter)
}
```{r}
> for(letter in x) {
+     print(letter)
+ }
[1] "a"
[1] "b"
[1] "c"
[1] "d"
```

for(i in 1:4) print(x[i])

#same as the first but the curly braces have been omitted, if the for loop only has a single expression you can omit the curly braces and put everything on one line. 

```{r}
> for(i in 1:4) print(x[i])
[1] "a"
[1] "b"
[1] "c"
[1] "d"
```

#Nested for loops

#for loops inside of a for loop
#nesting beyond 2-3 levels is often very difficult to read/understand

```{r}
x <- matrix(1:6, 2,3)
> for(i in seq_len(nrow(x))) {} #incorrect
> for(i in seq_len(nrow(x))) {
+     for(j in seq_len(ncol(x))) {
+     print(x[i, j])
+ }
+ }
[1] 1
[1] 3
[1] 5
[1] 2
[1] 4
[1] 6
```
```{r}
> x
     [,1] [,2] [,3]
[1,]    1    3    5
[2,]    2    4    6
```

#While loops

#while loops begin by testing a condition. If it is true, then they execute the loop body. Once the loop body is executed, the condition is tested again and so forth.

```{r}
> count <- 0
> while(count < 10) {
+     print(count)
+     count <- count + 1
+ } 
[1] 0
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
```

```{r}
 while (z>= 3 && z <=10) {
+     print(z)
+     coin <- rbinom(1,1,0.5)
+     if(coin == 1) {
+     z <- z+1
+     } else {
+     z <- z - 1
+     }
+ }
[1] 5  
[1] 4
[1] 3
```
# first z is printed (5)

 while (z>= 3 && z <=10) {
    coin <- rbinom(1,1,0.5)
print(z)
    if(coin == 1) {
  z <- z+1
   } else {
   z <- z - 1
    }
 }
 
 
 #Repeat, Next, Break
 
 #Repeat:
is a construct which initiates an infinite loop

#next is used to skip an iteration of a loop
#infinite loops should be generally avoided

#Functions (part 1)

f <- function(<argument>){
##Do something interesting
}

function() directive used to create function

they are R  objects of class "function"

"first class objects"  - can pass functions as arguments to other functions. functions can ben ested so you can define a function inside of another function. the return value of a functoin iis the last expression ni the function body to be evaluated. 

#Function Arguments

functions have named arguments which potentially have default values
- the formal arguments are the arguments included in the function definition
- the formals function returns a list of all the formal arguments of a function
- not every function call in R makes use of all the formal arguments
- Function arguments can be missing or might have default values


#Lexical Scoping

Lexical scoping in R means that: the values of free variables are searched for ni the environment in which the function was defined. 
What is an environment?
An environment is a collection of (symbol, value) pairs, i.e. x is a symbol and 3.14 might be its value
Every environment a parent environment; it is possible for an environment to have multple 'children'
the only environment without a parent is the empty environment
a function + an environment = a closure or function closure

if ur in a function and you encounter a free variable in a function what happens? you look at the environment in which the function was defined
if the value of a symbol is not found in the environment in which a function was defined, then the search is continued in the parent envrionment.
the search continues down the sequence of parent environments until we hit the top-level environment; this usually the global environment (workspace) or the namespace of a package.
After the top-level environment, the search continues down the search list untili we hit the empty environment. If a value for a given symbol cannot be found once the empty environment is arrived at, then an error is thrown. 

~~

in R you can define functions inside of other functions
a function can return a function as the return value
function was defined in another function, not in the global environment

```{r}
> make.power <- function(n) {
+     pow <- function(x) {
+     x^n
+ }
+ pow
+ }
> #make.power takes as input a number n and inside the make.power functoin is another function called pow,and pow takes an argument called x. pow function is gonna take the argument x and raise to the power n. and so make.power returns the function pow as its return value. inside the pow functioin x is a function argument but n is a free variable because its not defined inside the pow function. However n is defnied inside the make.power function and so since that's the environment in which pow is defined pow function will find the value of n inside its other environment. 
```

```{r}
> #i can call make.power and pass it a number like 3
> cube <- make.power(3)
> square <- make.power(2)
> cube(3)
[1] 27
> square(3)
[1] 9
```
you can look at the environment in which the function was defined by calling the ls function 
> ls(environment(cube))
[1] "n"   "pow"
> get('n', environment(cube))
[1] 3


```{r}
> f  <- function(x) {
+     g <- function(y){
+     y + z
+     }
+     z <- 4
+     x +  g(x)
+ }
> z  <-10
> f(3)
[1] 10
```
edX course

whats the difference between square brackets and parantheses in R?

```{r}
> library(dslabs)
> data(murders)
> sort(murders$total)
 [1]    2    4    5    5    7    8   11   12   12   16   19   21   22   27   32   36   38   53   63   65   67   84
[23]   93   93   97   97   99  111  116  118  120  135  142  207  219  232  246  250  286  293  310  321  351  364
[45]  376  413  457  517  669  805 1257
> murders$state[1:10]
 [1] "Alabama"              "Alaska"               "Arizona"              "Arkansas"            
 [5] "California"           "Colorado"             "Connecticut"          "Delaware"            
 [9] "District of Columbia" "Florida"             
> murders$abb[1:10]
 [1] "AL" "AK" "AZ" "AR" "CA" "CO" "CT" "DE" "DC" "FL"
> index <- order(murders$total)
> murders$abb[index]
 [1] "VT" "ND" "NH" "WY" "HI" "SD" "ME" "ID" "MT" "RI" "AK" "IA" "UT" "WV" "NE" "OR" "DE" "MN" "KS" "CO" "NM" "NV"
[23] "AR" "WA" "CT" "WI" "DC" "OK" "KY" "MA" "MS" "AL" "IN" "SC" "TN" "AZ" "NJ" "VA" "NC" "MD" "OH" "MO" "LA" "IL"
[45] "GA" "MI" "PA" "NY" "FL" "TX" "CA"
> max(murders$total)
[1] 1257
> i_max <- which.max(murders$total)
> i_max
[1] 5
> murders$state[i_max]
[1] "California" #California has the highest number of murders
```

rank function tells u about the ranks of the values in the original data set, prior to sorting.

from edX

library(dslabs)
data(murders)
sort(murders$total)

x <- c(31, 4, 15, 92, 65)
x
sort(x)    # puts elements in order

index <- order(x)    # returns index that will put x in order
x[index]    # rearranging by this index puts elements in order
order(x)

murders$state[1:10]
murders$abb[1:10]

index <- order(murders$total)
murders$abb[index]    # order abbreviations by total murders

max(murders$total)    # highest number of total murders
i_max <- which.max(murders$total)    # index with highest number of murders
murders$state[i_max]    # state name with highest number of total murders

x <- c(31, 4, 15, 92, 65)
x
rank(x)    # returns ranks (smallest to largest)

# The name of the state with the maximum population is found by doing the following
BL

# how to obtain the murder rate
murder_rate <- murders$total / murders$population * 100000

# ordering the states by murder rate, in decreasing order
murders$state[order(murder_rate, decreasing=TRUE)]

# defining murder rate as before
murder_rate <- murders$total / murders$population * 100000
# creating a logical vector that specifies if the murder rate in that state is less than or equal to 0.71
index <- murder_rate <= 0.71
# determining which states have murder rates less than or equal to 0.71
murders$state[index]
# calculating how many states have a murder rate less than or equal to 0.71
sum(index)

# creating the two logical vectors representing our conditions
west <- murders$region == "West"
safe <- murder_rate <= 1
# defining an index and identifying states with both conditions true
index <- safe & west
murders$state[index]
```{r}
index <- murder_rate <0.71
> index <- murder_rate <= 0.71
> index
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE
[19] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE
[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE
> murders$state[index]
[1] "Hawaii"        "Iowa"          "New Hampshire" "North Dakota"  "Vermont"      
> sum[index]
Error in sum[index] : object of type 'builtin' is not subsettable
> sum(index)
[1] 5
> index <- safe & west
Error: object 'safe' not found
> west <- murders$region == "West"
> safe <- murder_rate <= 1
> index <- safe & west
> murders$state[index]
[1] "Hawaii"  "Idaho"   "Oregon"  "Utah"    "Wyoming"
```

x <- c(FALSE, TRUE, FALSE, TRUE, TRUE, FALSE)
which(x)    # returns indices that are TRUE

# to determine the murder rate in Massachusetts we may do the following
index <- which(murders$state == "Massachusetts")
index
murder_rate[index]

# to obtain the indices and subsequent murder rates of New York, Florida, Texas, we do:
index <- match(c("New York", "Florida", "Texas"), murders$state)
index
murders$state[index]
murder_rate[index]

x <- c("a", "b", "c", "d", "e")
y <- c("a", "d", "f")
y %in% x

# to see if Boston, Dakota, and Washington are states
c("Boston", "Dakota", "Washington") %in% murders$state

#DATA WRANGLING

# installing and loading the dplyr package
install.packages("dplyr")
library(dplyr)

# adding a column with mutate
library(dslabs)
data("murders")
murders <- mutate(murders, rate = total / population * 100000)

# subsetting with filter
filter(murders, rate <= 0.71)

# selecting columns with select
new_table <- select(murders, state, region, rate)

# using the pipe
murders %>% select(state, region, rate) %>% filter(rate <= 0.71)

```{r}
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

murders <- mutate(murders, rate=total/population*100000)
> head(murders)
       state abb region population total     rate
1    Alabama  AL  South    4779736   135 2.824424
2     Alaska  AK   West     710231    19 2.675186
3    Arizona  AZ   West    6392017   232 3.629527
4   Arkansas  AR  South    2915918    93 3.189390
5 California  CA   West   37253956  1257 3.374138
6   Colorado  CO   West    5029196    65 1.292453
> filiter(murders, rate<= 0.71)
Error in filiter(murders, rate <= 0.71) : 
  could not find function "filiter"
> filter(murders, rate<=0.71)
          state abb        region population total      rate
1        Hawaii  HI          West    1360301     7 0.5145920
2          Iowa  IA North Central    3046355    21 0.6893484
3 New Hampshire  NH     Northeast    1316470     5 0.3798036
4  North Dakota  ND North Central     672591     4 0.5947151
5       Vermont  VT     Northeast     625741     2 0.3196211
> new_table <- select(murders,state,region,rate)
> filter(new_table, rate <=0.71)
          state        region      rate
1        Hawaii          West 0.5145920
2          Iowa North Central 0.6893484
3 New Hampshire     Northeast 0.3798036
4  North Dakota North Central 0.5947151
5       Vermont     Northeast 0.3196211
> murders %>% select(state, region, rate) %>% filter(rate <= 0.71)
          state        region      rate
1        Hawaii          West 0.5145920
2          Iowa North Central 0.6893484
3 New Hampshire     Northeast 0.3798036
4  North Dakota North Central 0.5947151
5       Vermont     Northeast 0.3196211
```

# creating a data frame with stringAsFactors = FALSE
grades <- data.frame(names = c("John", "Juan", "Jean", "Yao"), 
                     exam_1 = c(95, 80, 90, 85), 
                     exam_2 = c(90, 85, 85, 90),
                     stringsAsFactors = FALSE)
                     
```{r}
> grades <- data.frame(names=c("John", "Juan", "Jean", "Yao"), exam_1 = c(95, 80, 90, 85), exam_2 = c(90, 85, 85, 90))
> grades
  names exam_1 exam_2
1  John     95     90
2  Juan     80     85
3  Jean     90     85
4   Yao     85     90
> class(grades$names)
[1] "factor"
> grades <- data.frame(names=c("John", "Juan", "Jean", "Yao"), exam_1 = c(95, 80, 90, 85), exam_2 = c(90, 85, 85, 90), stringsAsFactors = FALSE)
> class(grades$names)
[1] "character"
```
 # a simple scatterplot of total murders versus population
x <- murders$population /10^6
y <- murders$total
plot(x, y)

# a histogram of murder rates
hist(murders$rate)

# boxplots of murder rates by region
boxplot(rate~region, data = murders)

```{r}
population_in_millions <- murders$population/10^6
> total_gun_murders <- murders$total
> plot(population_in_millions, total_gun_murders)
> hist(murders$rate)
> murders$state[which.max(murders$rate)]
[1] "District of Columbia"
> boxplot(rate~region, data = murders)
```

#Section 4 of R Basics

# an example showing the general structure of an if-else statement
a <- 0
if(a!=0){
  print(1/a)
} else{
  print("No reciprocal for 0.")
}

# an example that tells us which states, if any, have a murder rate less than 0.5
library(dslabs)
data(murders)
murder_rate <- murders$total / murders$population*100000
ind <- which.min(murder_rate)
if(murder_rate[ind] < 0.5){
  print(murders$state[ind]) 
} else{
  print("No state has murder rate that low")
}

# changing the condition to < 0.25 changes the result
if(murder_rate[ind] < 0.25){
  print(murders$state[ind]) 
} else{
  print("No state has a murder rate that low.")
}

# the ifelse() function works similarly to an if-else conditional
a <- 0
ifelse(a > 0, 1/a, NA)

# the ifelse() function is particularly useful on vectors
a <- c(0,1,2,-4,5)
result <- ifelse(a > 0, 1/a, NA)

# the ifelse() function is also helpful for replacing missing values
data(na_example)
no_nas <- ifelse(is.na(na_example), 0, na_example) 
sum(is.na(no_nas))

# the any() and all() functions evaluate logical vectors
z <- c(TRUE, TRUE, FALSE)
any(z)
all(z)
Annotate


# an example showing the general structure of an if-else statement
a <- 0
if(a!=0){
  print(1/a)
} else{
  print("No reciprocal for 0.")
}

# an example that tells us which states, if any, have a murder rate less than 0.5
library(dslabs)
data(murders)
murder_rate <- murders$total / murders$population*100000
ind <- which.min(murder_rate)
if(murder_rate[ind] < 0.5){
  print(murders$state[ind]) 
} else{
  print("No state has murder rate that low")
}

# changing the condition to < 0.25 changes the result
if(murder_rate[ind] < 0.25){
  print(murders$state[ind]) 
} else{
  print("No state has a murder rate that low.")
}

# the ifelse() function works similarly to an if-else conditional
a <- 0
ifelse(a > 0, 1/a, NA)

# the ifelse() function is particularly useful on vectors
a <- c(0,1,2,-4,5)
result <- ifelse(a > 0, 1/a, NA)

# the ifelse() function is also helpful for replacing missing values
data(na_example)
no_nas <- ifelse(is.na(na_example), 0, na_example) 
sum(is.na(no_nas))

# the any() and all() functions evaluate logical vectors
z <- c(TRUE, TRUE, FALSE)
any(z)
all(z)

#Section 4.3 Basic functions
# example of defining a function to compute the average of a vector x
avg <- function(x){
  s <- sum(x)
  n <- length(x)
  s/n
}

# we see that the above function and the pre-built R mean() function are identical
x <- 1:100
identical(mean(x), avg(x))

# variables inside a function are not defined in the workspace
s <- 3
avg(1:10)
s

# the general form of a function
my_function <- function(VARIABLE_NAME){
  perform operations on VARIABLE_NAME and calculate VALUE
  VALUE
}

# functions can have multiple arguments as well as default values
avg <- function(x, arithmetic = TRUE){
  n <- length(x)
  ifelse(arithmetic, sum(x)/n, prod(x)^(1/n))
}

my_function <- function (x) {
operations that operate on x which is defined by user of function value final line is returned
}

#SEction 4.4 For Loops

# creating a function that computes the sum of integers 1 through n
compute_s_n <- function(n){
  x <- 1:n
  sum(x)
}

# a very simple for-loop
for(i in 1:5){
  print(i)
}

# a for-loop for our summation
m <- 25
s_n <- vector(length = m) # create an empty vector
for(n in 1:m){
  s_n[n] <- compute_s_n(n)
}

# creating a plot for our summation function
n <- 1:m
plot(n, s_n)

# a table of values comparing our function to the summation formula
head(data.frame(s_n = s_n, formula = n*(n+1)/2))

# overlaying our function with the summation formula
plot(n, s_n)
lines(n, n*(n+1)/2)


Data Visualisation course

##Introduction

library(dslabs)
data(murders)
head(murders)

# load the dataset
library(dslabs)
data(heights)

# make a table of category proportions
prop.table(table(heights$sex))

a <- seq(min(my_data), max(my_data), length = 100)    # define range of values spanning the dataset
cdf_function <- function(x) {    # computes prob. for a single value
    mean(my_data <= x)
}
cdf_values <- sapply(a, cdf_function)
plot(a, cdf_values)

#Normal Distribution__

The normal distribution:
Is centered around one value, the mean
Is symmetric around the mean
Is defined completely by its mean (μ) and standard deviation ( σ )
Always has the same proportion of observations within a given distance of the mean (for example, 95% within 2 σ)
The standard deviation is the average distance between a value and the mean value.
Calculate the mean using the mean() function.
Calculate the standard deviation using the sd() function or manually. 
Standard units describe how many standard deviations a value is away from the mean. The z-score, or number of standard deviations an observation x is away from the mean μ:
Z=
x−μ
σ
 

Compute standard units with the scale() function.
Important: to calculate the proportion of values that meet a certain condition, use the mean() function on a logical vector. Because TRUE is converted to 1 and FALSE is converted to 0, taking the mean of this vector yields the proportion of TRUE.
Equation for the normal distribution
The normal distribution is mathematically defined by the following formula for any mean μ and standard deviation σ:

Pr(a<x<b)=∫
b
a
1
√
2π
σ
 
e−
1
2
 
(
x−μ
σ
 
)2dx

Code
# define x as vector of male heights
library(tidyverse)
library(dslabs)
data(heights)
index <- heights$sex=="Male"
x <- heights$height[index]

# calculate the mean and standard deviation manually
average <- sum(x)/length(x)
SD <- sqrt(sum((x - average)^2)/length(x))

# built-in mean and sd functions - note that the audio and printed values disagree
average <- mean(x)
SD <- sd(x)
c(average = average, SD = SD)

# calculate standard units
z <- scale(x)

# calculate proportion of values within 2 SD of mean
mean(abs(z) < 2)
Note about the sd function
The built-in R function sd() calculates the standard deviation, but it divides by length(x)-1 instead of length(x). When the length of the list is large, this difference is negligible and you can use the built-in sd() function. Otherwise, you should compute σ by hand. For this course series, assume that you should use the sd() function unless you are told not to do so.

The scale function converts a vector of approximately normally distributed values into z-scores.

z <- scale(x)
You can compute the proportion of observations that are within 2 standard deviations of the mean like this:

mean(abs(z) < 2)

#Normal cdf and pnorm

The normal distribution has a mathematically defined CDF which can be computed in R with the function pnorm().
pnorm(a, avg, s) gives the value of the cumulative distribution function  𝐹(𝑎)  for the normal distribution defined by average avg and standard deviation s.
We say that a random quantity is normally distributed with average avg and standard deviation s if the approximation pnorm(a, avg, s) holds for all values of a.
If we are willing to use the normal approximation for height, we can estimate the distribution simply from the mean and standard deviation of our values.
If we treat the height data as discrete rather than categorical, we see that the data are not very useful because integer values are more common than expected due to rounding. This is called discretization.
With rounded data, the normal approximation is particularly useful when computing probabilities of intervals of length 1 that include exactly one integer.
Code: Using pnorm to calculate probabilities
Given male heights x:

library(tidyverse)
library(dslabs)
data(heights)
x <- heights %>% filter(sex=="Male") %>% pull(height)
We can estimate the probability that a male is taller than 70.5 inches with:

1 - pnorm(70.5, mean(x), sd(x))
Code: Discretization and the normal approximation
# plot distribution of exact heights in data
plot(prop.table(table(x)), xlab = "a = Height in inches", ylab = "Pr(x = a)")

# probabilities in actual data over length 1 ranges containing an integer
mean(x <= 68.5) - mean(x <= 67.5)
mean(x <= 69.5) - mean(x <= 68.5)
mean(x <= 70.5) - mean(x <= 69.5)

# probabilities in normal approximation match well
pnorm(68.5, mean(x), sd(x)) - pnorm(67.5, mean(x), sd(x))
pnorm(69.5, mean(x), sd(x)) - pnorm(68.5, mean(x), sd(x))
pnorm(70.5, mean(x), sd(x)) - pnorm(69.5, mean(x), sd(x))

# probabilities in actual data over other ranges don't match normal approx as well
mean(x <= 70.9) - mean(x <= 70.1)
pnorm(70.9, mean(x), sd(x)) - pnorm(70.1, mean(x), sd(x))




